{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group1 is:  3903 , Group2 is:  3979\n"
     ]
    }
   ],
   "source": [
    "# from matplotlib import pyplot\n",
    "import os\n",
    "\n",
    "#define a function to count the document number \n",
    "def Count(dirname):\n",
    "  count=0\n",
    "  for item in os.listdir(dirname):\n",
    "    count+=1\n",
    "  return count\n",
    "\n",
    "counter=[]\n",
    "\n",
    "#plot the histogram for 20 topics\n",
    "for dir in os.listdir('20news-bydate-train'):\n",
    "  dir_name='20news-bydate-train/'+dir\n",
    "  count1=Count(dir_name)\n",
    "  counter.append(count1)\n",
    "\n",
    "i=0;\n",
    "\n",
    "for dir in os.listdir('20news-bydate-test'):\n",
    "  #print counter[i],'\\n'\n",
    "  dir_name='20news-bydate-test/'+dir\n",
    "  count2=Count(dir_name)\n",
    "  counter[i]+=count2\n",
    "  #print counter[i],'\\n'\n",
    "  i+=1\n",
    "  \n",
    "#count the document number for the two groups\n",
    "new_counter=[0,0]\n",
    "for dir in os.listdir('20news-bydate-train'):\n",
    "  if(dir=='comp.graphics' or dir=='comp.os.ms-windows.misc' or dir=='comp.sys.ibm.pc.hardware' or dir=='comp.sys.mac.hardware'):\n",
    "    dir_name='20news-bydate-train/'+dir\n",
    "    count1=Count(dir_name)\n",
    "    new_counter[0]+=count1\n",
    "    #print (new_counter[0],'\\n')\n",
    "  if(dir=='rec.autos' or dir=='rec.motorcycles' or dir=='rec.sport.baseball' or dir=='rec.sport.hockey'):\n",
    "    dir_name='20news-bydate-train/'+dir\n",
    "    count1=Count(dir_name)\n",
    "    new_counter[1]+=count1\n",
    "    #print (new_counter[1],'\\n')\n",
    "    \n",
    "for dir in os.listdir('20news-bydate-test'):\n",
    "  if(dir=='comp.graphics' or dir=='comp.os.ms-windows.misc' or dir=='comp.sys.ibm.pc.hardware' or dir=='comp.sys.mac.hardware'):\n",
    "    dir_name='20news-bydate-test/'+dir\n",
    "    count2=Count(dir_name)\n",
    "    new_counter[0]+=count2\n",
    "    #print (new_counter[0],'\\n')\n",
    "  if(dir=='rec.autos' or dir=='rec.motorcycles' or dir=='rec.sport.baseball' or dir=='rec.sport.hockey'):\n",
    "    dir_name='20news-bydate-test/'+dir\n",
    "    count2=Count(dir_name)\n",
    "    new_counter[1]+=count2\n",
    "    #print (new_counter[1],'\\n')\n",
    "\n",
    "print ('Group1 is: ',new_counter[0],', Group2 is: ',new_counter[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ziyin\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "n = 20\n",
    "values = (counter[0],counter[1],counter[2],counter[3],counter[4],counter[5],counter[6],counter[7],counter[8],counter[9],counter[10],counter[11],counter[12],counter[13],counter[14],counter[15],counter[16],counter[17],counter[18],counter[19])\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n)\n",
    "bar_width = 0.35\n",
    "opacity = 1.0\n",
    "bars = plt.bar(index, values, bar_width,alpha = opacity, color = 'b')\n",
    "plt.xlabel('Topics')\n",
    "plt.xlabel('\\nDocuments')\n",
    "plt.title('Number of documents per topic')\n",
    "plt.xticks(index + bar_width, ('atheism', 'graphics', 'windows.\\nmisc', 'pc.\\nhardware', 'mac.\\nhardware', 'windows.x', 'forsale', 'autos', 'motorcycles', 'sport.\\nbaseball', 'sport.\\nhockey', 'crypt', 'electronics', 'med', 'space', 'christian', 'guns', 'mideast', 'politics.\\nmisc', 'religion.\\nmisc'))\n",
    "plt.ylim(0,1000)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 72399)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "import re\n",
    "import nltk \n",
    "import string\n",
    "#nltk.download()\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def tokenizer_fun(text):\n",
    "    new_text = re.sub(r'[^A-Za-z]', \" \", text)\n",
    "    tokens =[word for sent in nltk.sent_tokenize(new_text) for word in nltk.word_tokenize(sent)]\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]{2,}', token):\n",
    "            new_tokens.append(token)     \n",
    "    stem = [stemmer.stem(t) for t in new_tokens]\n",
    "    return stem\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "all_data = fetch_20newsgroups(subset='all', shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TFxIDF = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}',)\n",
    "TFxIDF_data = TFxIDF.fit_transform(all_data.data)\n",
    "count = TFxIDF_data.shape\n",
    "\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['scsi', 'mb', 'drive', 'control', 'work', 'use', 'problem', 'ani', 'disk', 'card'])\n",
      "dict_keys(['drive', 'like', 'know', 'mac', 'work', 'use', 'problem', 'ani', 'appl', 'monitor'])\n",
      "dict_keys(['sell', 'pleas', 'ship', 'offer', 'price', 'drive', 'use', 'includ', 'sale', 'new'])\n",
      "dict_keys(['say', 'god', 'church', 'christian', 'peopl', 'believ', 'think', 'sin', 'jesus', 'know'])\n"
     ]
    }
   ],
   "source": [
    "my_list=['comp.sys.ibm.pc.hardware','comp.sys.mac.hardware','misc.forsale','soc.religion.christian']\n",
    "\n",
    "for category in my_list:\n",
    "    categories = [category]\n",
    "    sub_data = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "    TFxIDF_sub = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, max_features=10, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}')\n",
    "    sub_count = TFxIDF_sub.fit_transform(sub_data.data)\n",
    "    #print (sub_count)\n",
    "    print (TFxIDF_sub.vocabulary_.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Problem(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "X = TruncatedSVD(n_components=50, algorithm='arpack')\n",
    "LSI = X.fit_transform(TFxIDF_data)\n",
    "#print (LSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Problem(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions to get data or LSI for train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = ['comp.graphics','comp.os.ms-windows.misc','comp.sys.ibm.pc.hardware','comp.sys.ibm.pc.hardware','rec.autos','rec.motorcycles','rec.sport.baseball','rec.sport.hockey']\n",
    "\n",
    "def data_fun(train_or_test):\n",
    "    if(train_or_test == 'train'):\n",
    "        data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "    if(train_or_test == 'test'):\n",
    "        data = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "    return data  \n",
    "\n",
    "def LSI_fun(train_or_test):\n",
    "    if(train_or_test == 'train'):\n",
    "        data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "        TFxIDF_sub = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}',)\n",
    "        TFxIDF_sub_data = TFxIDF_sub.fit_transform(data.data)\n",
    "        Y = TruncatedSVD(n_components=50, algorithm='arpack')\n",
    "        sub_LSI = Y.fit_transform(TFxIDF_sub_data)\n",
    "    if(train_or_test == 'test'):\n",
    "        data = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "        TFxIDF_sub = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}',)\n",
    "        TFxIDF_sub_data = TFxIDF_sub.fit_transform(data.data)\n",
    "        Y = TruncatedSVD(n_components=50, algorithm='arpack')\n",
    "        sub_LSI = Y.fit_transform(TFxIDF_sub_data)\n",
    "    return sub_LSI \n",
    "\n",
    "#new_LSI = LSI_fun('train')\n",
    "#print (new_LSI.shape)\n",
    "\n",
    "#new_LSI = LSI_fun('test')\n",
    "#print (new_LSI.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 7 4 6 1 2 4 6 0 7 2 0 7 5 7 5 2 5 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "lin_clf = svm.LinearSVC()\n",
    "# print(all_data.target)\n",
    "train_LSI = LSI_fun('train')\n",
    "train_set = data_fun('train')\n",
    "\n",
    "train_target_group = [ int(x / 4) for x in train_set.target]\n",
    "# print(train_target_group)\n",
    "print(train_set.target[0:20])\n",
    "# lin_clf.fit(train_LSI, train_set.target)\n",
    "lin_clf.fit(train_LSI, train_target_group)\n",
    "#lin_clf.fit(train_LSI, train_set.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2765, 50)\n",
      "[1 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "test_LSI = LSI_fun('test')\n",
    "print(test_LSI.shape)\n",
    "svm_predicted = lin_clf.predict(test_LSI)\n",
    "print (svm_predicted[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "test_set = data_fun('test')\n",
    "test_target_group = [ int(x / 4) for x in test_set.target]\n",
    "y_score_test = lin_clf.decision_function(test_LSI)\n",
    "\n",
    "\n",
    "#print(test_target_group[0:10])\n",
    "#print(y_score_test.shape)\n",
    "#print(y_score_test[0:10])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_target_group, y_score_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 863,  312],\n",
       "       [  64, 1526]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_target_group, svm_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864014466546\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "svm_accuracy = accuracy_score(test_target_group, svm_predicted)\n",
    "print (svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.830250272035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "svm_precision_score = precision_score(test_target_group, svm_predicted)\n",
    "print (svm_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959748427673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "svm_recall_score = recall_score(test_target_group, svm_predicted)\n",
    "print (svm_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM-Recall and Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.64035441  0.64020951  0.64046755  0.64072581  0.64098427  0.64124294\n",
      "  0.64150182  0.6417609   0.6420202   0.64227971]\n",
      "[ 1.          0.99937107  0.99937107  0.99937107  0.99937107  0.99937107\n",
      "  0.99937107  0.99937107  0.99937107  0.99937107]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "precision, recall, _ = precision_recall_curve(test_target_group,y_score_test)\n",
    "average_precision = average_precision_score(test_target_group, y_score_test)\n",
    "print (precision[0:10])\n",
    "print (recall[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.cross_validation.KFold(n=4154, n_folds=5, shuffle=False, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "kf = KFold(len(train_target_group), n_folds=5,shuffle=False,random_state=None)\n",
    "len(kf)\n",
    "print(kf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "#initialize a matrix with 7 rows(lamda) and 5 columns(5 validation)\n",
    "matrix = [[0]*7 for i in range(5)]\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "    X_train, X_test = train_LSI[train_index], train_LSI[test_index]\n",
    "    for k in [-3, -2, -1, 0, 1, 2, 3]:\n",
    "        X_train_target_group = [ int(x / 4) for x in train_set.target[train_index]]\n",
    "        X_test_target_group = [ int(x / 4) for x in train_set.target[test_index]]\n",
    "        \n",
    "        soft_svm_clf = svm.LinearSVC(C=10**k)\n",
    "        soft_svm_clf.fit(X_train, X_train_target_group)\n",
    "        score = soft_svm_clf.score(X_test, X_test_target_group)        \n",
    "        matrix[i][j]=score\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "    j=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best penalty value is 100\n"
     ]
    }
   ],
   "source": [
    "ave_score = list(map(lambda x: (x[0]+x[1]+x[2]+x[3]+x[4])/5, zip(matrix[0], matrix[1], matrix[2], matrix[3], matrix[4])))\n",
    "#print average_s\n",
    "value = max(ave_score)\n",
    "index=ave_score.index(value)\n",
    "#print index\n",
    "penalty = [-3, -2, -1, 0, 1, 2, 3]\n",
    "print ('The best penalty value is',10**penalty[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.852802893309\n"
     ]
    }
   ],
   "source": [
    "soft_clf = svm.LinearSVC(C=10**1)\n",
    "soft_clf.fit(train_LSI, train_target_group)\n",
    "soft_svm_predicted = soft_clf.predict(test_LSI)\n",
    "\n",
    "score = soft_clf.score(test_LSI, test_target_group)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft_SVM Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 847,  328],\n",
       "       [  79, 1511]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test_target_group, soft_svm_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft_clf-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.852802893309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "soft_clf_accuracy = accuracy_score(test_target_group, soft_svm_predicted)\n",
    "print (soft_clf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821642196846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "soft_clf_precision_score = precision_score(test_target_group, soft_svm_predicted)\n",
    "print (soft_clf_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.950314465409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "soft_clf_recall_score = recall_score(test_target_group, soft_svm_predicted)\n",
    "print (soft_clf_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2765,)\n",
      "[1 0 1 0 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(train_LSI, train_target_group)\n",
    "nb_predicted = nb_clf.predict(test_LSI)\n",
    "print (nb_predicted.shape)\n",
    "print (nb_predicted[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2765,)\n",
      "[  9.99998535e-01   2.41728915e-06   9.99995110e-01   8.35444547e-19\n",
      "   1.09664432e-04   2.34099449e-53   9.99975396e-01   1.35612443e-07\n",
      "   4.98885655e-01   9.99979288e-01]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "test_set = data_fun('test')\n",
    "test_target_group = [ int(x / 4) for x in test_set.target]\n",
    "y_score_test_nb = nb_clf.predict_proba(test_LSI)[:,1]\n",
    "\n",
    "\n",
    "print(y_score_test_nb.shape)\n",
    "print(y_score_test_nb[0:10])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_target_group, y_score_test_nb)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[936, 239],\n",
       "       [764, 826]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test_target_group, nb_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.637251356239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nb_accuracy = accuracy_score(test_target_group, nb_predicted)\n",
    "print (nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77558685446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "nb_precision_score = precision_score(test_target_group, nb_predicted)\n",
    "print (nb_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.519496855346\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "nb_recall_score = recall_score(test_target_group, nb_predicted)\n",
    "print (nb_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB-Recall and Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57504521  0.70386007  0.70392749  0.70381587  0.70345664  0.70309654\n",
      "  0.70291616  0.70237371  0.70365854  0.7045177 ]\n",
      "[ 1.          0.73396226  0.7327044   0.73081761  0.72955975  0.72830189\n",
      "  0.72767296  0.72578616  0.72578616  0.72578616]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "y_score_test_nb = nb_clf.predict_proba(test_LSI)[:,1]\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "precision, recall, _ = precision_recall_curve(test_target_group,y_score_test_nb)\n",
    "average_precision = average_precision_score(test_target_group, y_score_test_nb)\n",
    "print (precision[0:10])\n",
    "print (recall[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### LR classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2765,)\n",
      "[1 0 1 0 0 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(train_LSI, train_target_group)\n",
    "lr_predicted = logreg.predict(test_LSI)\n",
    "print (lr_predicted.shape)\n",
    "print (lr_predicted[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2765,)\n",
      "[  4.70921762 -19.2542064    4.15699709  -5.53790364 -30.72647309\n",
      "  17.67154364   3.96866553 -24.63030585  -6.16904487   5.70334832]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "test_set = data_fun('test')\n",
    "test_target_group = [ int(x / 4) for x in test_set.target]\n",
    "y_score_test_lr = logreg.decision_function(test_LSI)\n",
    "#y_score_test_lr = logreg.predict_proba(test_LSI)[:,1]\n",
    "\n",
    "print(y_score_test_lr.shape)\n",
    "print(y_score_test_lr[0:10])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_target_group, y_score_test_lr)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 850,  325],\n",
       "       [ 124, 1466]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test_target_group, lr_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.837613019892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "lr_accuracy = accuracy_score(test_target_group, lr_predicted)\n",
    "print (lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818537130095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "lr_precision_score = precision_score(test_target_group, lr_predicted)\n",
    "print (lr_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.922012578616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "lr_recall_score = recall_score(test_target_group, lr_predicted)\n",
    "print (lr_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR-Recall and Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.61795569  0.61780715  0.61804745  0.61828794  0.61852861  0.61876947\n",
      "  0.61901052  0.61925175  0.61949318  0.61973479]\n",
      "[ 1.          0.99937107  0.99937107  0.99937107  0.99937107  0.99937107\n",
      "  0.99937107  0.99937107  0.99937107  0.99937107]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "y_score_test_lr = logreg.decision_function(test_LSI)\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "precision, recall, _ = precision_recall_curve(test_target_group,y_score_test_lr)\n",
    "average_precision = average_precision_score(test_target_group, y_score_test_lr)\n",
    "print (precision[0:10])\n",
    "print (recall[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions to get data or LSI for train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories_i = ['comp.sys.ibm.pc.hardware','comp.sys.mac.hardware','misc.forsale','soc.religion.christian']\n",
    "\n",
    "def data_fun_i(train_or_test):\n",
    "    if(train_or_test == 'train'):\n",
    "        data = fetch_20newsgroups(subset='train', categories=categories_i, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "    if(train_or_test == 'test'):\n",
    "        data = fetch_20newsgroups(subset='test', categories=categories_i, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "    return data\n",
    "\n",
    "def LSI_fun_i(train_or_test):\n",
    "    if(train_or_test == 'train'):\n",
    "        data = fetch_20newsgroups(subset='train', categories=categories_i, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "        TFxIDF_sub = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}',)\n",
    "        TFxIDF_sub_data = TFxIDF_sub.fit_transform(data.data)\n",
    "        Y = TruncatedSVD(n_components=50, algorithm='arpack')\n",
    "        sub_LSI = Y.fit_transform(TFxIDF_sub_data)\n",
    "    if(train_or_test == 'test'):\n",
    "        data = fetch_20newsgroups(subset='test', categories=categories_i, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "        TFxIDF_sub = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}',)\n",
    "        TFxIDF_sub_data = TFxIDF_sub.fit_transform(data.data)\n",
    "        Y = TruncatedSVD(n_components=50, algorithm='arpack')\n",
    "        sub_LSI = Y.fit_transform(TFxIDF_sub_data)\n",
    "    return sub_LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier \n",
    "from sklearn.multiclass import OneVsOneClassifier \n",
    "from sklearn.svm import LinearSVC\n",
    "train_LSI_i = LSI_fun_i('train')\n",
    "train_set_i = data_fun_i('train')\n",
    "test_LSI_i = LSI_fun_i('test')\n",
    "test_set_i = data_fun_i('test')\n",
    "#train_target_group_i = [ int(x / 10) for x in train_set_i.target]\n",
    "#test_target_group_i = [int(x / 10) for x in test_set_i.target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one vs rest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 ..., 0 2 3]\n"
     ]
    }
   ],
   "source": [
    "ovr_classifier_i = OneVsRestClassifier (LinearSVC())\n",
    "ovr_classifier_i.fit(train_LSI_i, train_set_i.target)\n",
    "ovr_predict_i = ovr_classifier_i.predict(test_LSI_i)\n",
    "#print (ovr_predict_i[0:4])\n",
    "print (ovr_predict_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVR-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[149, 178,  60,   5],\n",
       "       [124,  94, 140,  27],\n",
       "       [ 37,  35, 308,  10],\n",
       "       [  4,   5,  28, 361]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_set_i.target, ovr_predict_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVR-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582747603834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ovr_accuracy = accuracy_score(test_set_i.target, ovr_predict_i)\n",
    "print (ovr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.563982043464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "ovr_precision_score = precision_score(test_set_i.target, ovr_predict_i,average='weighted')\n",
    "print (ovr_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582747603834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "ovr_recall_score = recall_score(test_set_i.target, ovr_predict_i,average='weighted')\n",
    "print (ovr_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one vs one classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1565,)\n",
      "[2 0 2 ..., 0 2 3]\n"
     ]
    }
   ],
   "source": [
    "ovo_classifier_i = OneVsOneClassifier (LinearSVC())\n",
    "ovo_classifier_i.fit(train_LSI_i, train_set_i.target)\n",
    "ovo_predict_i = ovo_classifier_i.predict(test_LSI_i)\n",
    "print (ovo_predict_i.shape)\n",
    "print (ovo_predict_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVO-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[156, 175,  59,   2],\n",
       "       [145,  94, 136,  10],\n",
       "       [ 37,  37, 310,   6],\n",
       "       [  5,  10,  35, 348]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_set_i.target, ovo_predict_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVO-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.580191693291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ovo_accuracy = accuracy_score(test_set_i.target, ovo_predict_i)\n",
    "print (ovo_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.571965590504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "ovo_precision_score = precision_score(test_set_i.target, ovo_predict_i,average='weighted')\n",
    "print (ovo_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.580191693291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "ovo_recall_score = recall_score(test_set_i.target, ovo_predict_i,average='weighted')\n",
    "print (ovo_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Multiclass Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1565,)\n",
      "[2 0 3 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classifier_i = GaussianNB()\n",
    "nb_classifier_i.fit(train_LSI_i, train_set_i.target)\n",
    "nb_predict_i = nb_classifier_i.predict(test_LSI_i)\n",
    "print (nb_predict_i.shape)\n",
    "print (nb_predict_i[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB-Multi Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[137, 161,  72,  22],\n",
       "       [109, 127, 105,  44],\n",
       "       [ 79,  45, 204,  62],\n",
       "       [ 97,  18,  56, 227]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_set_i.target, nb_predict_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB-Multi-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.444089456869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nb_accuracy = accuracy_score(test_set_i.target, nb_predict_i)\n",
    "print (nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.449276631965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "nb_precision_score = precision_score(test_set_i.target, nb_predict_i,average='weighted')\n",
    "print (nb_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.444089456869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "nb_recall_score = recall_score(test_set_i.target, nb_predict_i,average='weighted')\n",
    "print (nb_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
