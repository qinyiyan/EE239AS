{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot\n",
    "import os\n",
    "\n",
    "#define a function to count the document number \n",
    "def Count(dirname):\n",
    "  count=0\n",
    "  for item in os.listdir(dirname):\n",
    "    count+=1\n",
    "  return count\n",
    "\n",
    "counter=[]\n",
    "\n",
    "#plot the histogram for 20 topics\n",
    "for dir in os.listdir('20news-bydate-train'):\n",
    "  dir_name='20news-bydate-train/'+dir\n",
    "  count1=Count(dir_name)\n",
    "  counter.append(count1)\n",
    "\n",
    "i=0;\n",
    "\n",
    "for dir in os.listdir('20news-bydate-test'):\n",
    "  #print counter[i],'\\n'\n",
    "  dir_name='20news-bydate-test/'+dir\n",
    "  count2=Count(dir_name)\n",
    "  counter[i]+=count2\n",
    "  #print counter[i],'\\n'\n",
    "  i+=1\n",
    "  \n",
    "#count the document number for the two groups\n",
    "new_counter=[0,0]\n",
    "for dir in os.listdir('20news-bydate-train'):\n",
    "  if(dir=='comp.graphics' or dir=='comp.os.ms-windows.misc' or dir=='comp.sys.ibm.pc.hardware' or dir=='comp.sys.mac.hardware'):\n",
    "    dir_name='20news-bydate-train/'+dir\n",
    "    count1=Count(dir_name)\n",
    "    new_counter[0]+=count1\n",
    "    #print (new_counter[0],'\\n')\n",
    "  if(dir=='rec.autos' or dir=='rec.motorcycles' or dir=='rec.sport.baseball' or dir=='rec.sport.hockey'):\n",
    "    dir_name='20news-bydate-train/'+dir\n",
    "    count1=Count(dir_name)\n",
    "    new_counter[1]+=count1\n",
    "    #print (new_counter[1],'\\n')\n",
    "    \n",
    "for dir in os.listdir('20news-bydate-test'):\n",
    "  if(dir=='comp.graphics' or dir=='comp.os.ms-windows.misc' or dir=='comp.sys.ibm.pc.hardware' or dir=='comp.sys.mac.hardware'):\n",
    "    dir_name='20news-bydate-test/'+dir\n",
    "    count2=Count(dir_name)\n",
    "    new_counter[0]+=count2\n",
    "    #print (new_counter[0],'\\n')\n",
    "  if(dir=='rec.autos' or dir=='rec.motorcycles' or dir=='rec.sport.baseball' or dir=='rec.sport.hockey'):\n",
    "    dir_name='20news-bydate-test/'+dir\n",
    "    count2=Count(dir_name)\n",
    "    new_counter[1]+=count2\n",
    "    #print (new_counter[1],'\\n')\n",
    "\n",
    "print ('Group1 is: ',new_counter[0],', Group2 is: ',new_counter[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "n = 20\n",
    "values = (counter[0],counter[1],counter[2],counter[3],counter[4],counter[5],counter[6],counter[7],counter[8],counter[9],counter[10],counter[11],counter[12],counter[13],counter[14],counter[15],counter[16],counter[17],counter[18],counter[19])\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n)\n",
    "bar_width = 0.35\n",
    "opacity = 1.0\n",
    "bars = plt.bar(index, values, bar_width,alpha = opacity, color = 'b')\n",
    "plt.xlabel('Topics')\n",
    "plt.xlabel('\\nDocuments')\n",
    "plt.title('Number of documents per topic')\n",
    "plt.xticks(index + bar_width, ('atheism', 'graphics', 'windows.\\nmisc', 'pc.\\nhardware', 'mac.\\nhardware', 'windows.x', 'forsale', 'autos', 'motorcycles', 'sport.\\nbaseball', 'sport.\\nhockey', 'crypt', 'electronics', 'med', 'space', 'christian', 'guns', 'mideast', 'politics.\\nmisc', 'religion.\\nmisc'))\n",
    "plt.ylim(0,1000)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 72399)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "import re\n",
    "import nltk \n",
    "import string\n",
    "#nltk.download()\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def tokenizer_fun(text):\n",
    "    new_text = re.sub(r'[^A-Za-z]', \" \", text)\n",
    "    tokens =[word for sent in nltk.sent_tokenize(new_text) for word in nltk.word_tokenize(sent)]\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]{2,}', token):\n",
    "            new_tokens.append(token)     \n",
    "    stem = [stemmer.stem(t) for t in new_tokens]\n",
    "    return stem\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "all_data = fetch_20newsgroups(subset='all', shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TFxIDF = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}',)\n",
    "TFxIDF_data = TFxIDF.fit_transform(all_data.data)\n",
    "count = TFxIDF_data.shape\n",
    "\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'drive', u'problem', u'disk', u'work', u'card', u'mb', u'ani', u'scsi', u'use', u'control']\n",
      "[u'ani', u'drive', u'know', u'like', u'problem', u'work', u'use', u'mac', u'appl', u'monitor']\n",
      "[u'new', u'offer', u'drive', u'ship', u'sale', u'sell', u'includ', u'price', u'pleas', u'use']\n",
      "[u'peopl', u'say', u'believ', u'church', u'jesus', u'think', u'god', u'christian', u'sin', u'know']\n"
     ]
    }
   ],
   "source": [
    "my_list=['comp.sys.ibm.pc.hardware','comp.sys.mac.hardware','misc.forsale','soc.religion.christian']\n",
    "\n",
    "for category in my_list:\n",
    "    categories = [category]\n",
    "    sub_data = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "    TFxIDF_sub = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, max_features=10, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}')\n",
    "    sub_count = TFxIDF_sub.fit_transform(sub_data.data)\n",
    "    #print (sub_count)\n",
    "    print (TFxIDF_sub.vocabulary_.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Problem(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "X = TruncatedSVD(n_components=50, algorithm='arpack')\n",
    "LSI = X.fit_transform(TFxIDF_data)\n",
    "#print (LSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Problem(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions to get data or LSI for train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = ['comp.graphics','comp.os.ms-windows.misc','comp.sys.ibm.pc.hardware','comp.sys.mac.hardware','rec.autos','rec.motorcycles','rec.sport.baseball','rec.sport.hockey']\n",
    "\n",
    "def data_fun(train_or_test):\n",
    "    if(train_or_test == 'train'):\n",
    "        data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "    if(train_or_test == 'test'):\n",
    "        data = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "    return data  \n",
    "\n",
    "def LSI_fun(train_or_test):\n",
    "    if(train_or_test == 'train'):\n",
    "        data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "        TFxIDF_sub = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}',)\n",
    "        TFxIDF_sub_data = TFxIDF_sub.fit_transform(data.data)\n",
    "        Y = TruncatedSVD(n_components=50, algorithm='arpack')\n",
    "        sub_LSI = Y.fit_transform(TFxIDF_sub_data)\n",
    "    if(train_or_test == 'test'):\n",
    "        data = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "        TFxIDF_sub = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}',)\n",
    "        TFxIDF_sub_data = TFxIDF_sub.fit_transform(data.data)\n",
    "        Y = TruncatedSVD(n_components=50, algorithm='arpack')\n",
    "        sub_LSI = Y.fit_transform(TFxIDF_sub_data)\n",
    "    return sub_LSI \n",
    "\n",
    "#new_LSI = LSI_fun('train')\n",
    "#print (new_LSI.shape)\n",
    "\n",
    "#new_LSI = LSI_fun('test')\n",
    "#print (new_LSI.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "lin_clf = svm.LinearSVC()\n",
    "# print(all_data.target)\n",
    "train_LSI = LSI_fun('train')\n",
    "train_set = data_fun('train')\n",
    "\n",
    "train_target_group = [ int(x / 4) for x in train_set.target]\n",
    "# print(train_target_group)\n",
    "#print(train_set.target[0:20])\n",
    "# lin_clf.fit(train_LSI, train_set.target)\n",
    "lin_clf.fit(train_LSI, train_target_group)\n",
    "#lin_clf.fit(train_LSI, train_set.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3150, 50)\n",
      "[1 0 0 0 0 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "test_LSI = LSI_fun('test')\n",
    "print(test_LSI.shape)\n",
    "svm_predicted = lin_clf.predict(test_LSI)\n",
    "print (svm_predicted[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "test_set = data_fun('test')\n",
    "test_target_group = [ int(x / 4) for x in test_set.target]\n",
    "y_score_test = lin_clf.decision_function(test_LSI)\n",
    "\n",
    "#print(test_target_group[0:10])\n",
    "#print(y_score_test.shape)\n",
    "#print(y_score_test[0:10])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_target_group, y_score_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC_SVM Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_target_group, svm_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "svm_accuracy = accuracy_score(test_target_group, svm_predicted)\n",
    "print (svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "svm_precision_score = precision_score(test_target_group, svm_predicted)\n",
    "print (svm_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "svm_recall_score = recall_score(test_target_group, svm_predicted)\n",
    "print (svm_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM-Recall and Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "precision, recall, _ = precision_recall_curve(test_target_group,y_score_test)\n",
    "average_precision = average_precision_score(test_target_group, y_score_test)\n",
    "#print (precision[0:10])\n",
    "#print (recall[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best parameter lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "kf = KFold(len(train_target_group), n_folds=5,shuffle=False,random_state=None)\n",
    "len(kf)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "#initialize a matrix with 7 rows(lamda) and 5 columns(5 validation)\n",
    "scores = [[0]*7 for i in range(5)]\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "    X_train, X_test = train_LSI[train_index], train_LSI[test_index]\n",
    "    for k in [-3, -2, -1, 0, 1, 2, 3]:\n",
    "        X_train_target_group = [ int(x / 4) for x in train_set.target[train_index]]\n",
    "        X_test_target_group = [ int(x / 4) for x in train_set.target[test_index]]\n",
    "        \n",
    "        soft_svm_clf = svm.LinearSVC(C=10**k)\n",
    "        soft_svm_clf.fit(X_train, X_train_target_group)\n",
    "        scores[i][j]= soft_svm_clf.score(X_test, X_test_target_group)        \n",
    "        j=j+1\n",
    "    i=i+1\n",
    "    j=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ave_score = list(map(lambda x: (x[0]+x[1]+x[2]+x[3]+x[4])/5, zip(scores[0], scores[1], scores[2], scores[3], scores[4])))\n",
    "max_score = max(ave_score)\n",
    "index=ave_score.index(max_score)\n",
    "r = [-3, -2, -1, 0, 1, 2, 3]\n",
    "print ('The best lambda is',10**r[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best parameter lambda  (another method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "penalty = [-3, -2, -1, 0, 1, 2, 3]\n",
    "for k in penalty:\n",
    "    soft_svm_clf = svm.LinearSVC(C=10**k)\n",
    "    scores = cross_validation. cross_val_score(soft_svm_clf, train_LSI, train_target_group, cv=5)\n",
    "    print np.mean(scores)\n",
    "max_score = max(scores)\n",
    "index=scores.index(max_score)\n",
    "penalty = [-3, -2, -1, 0, 1, 2, 3]\n",
    "print ('The best lambda is',10**penalty[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft_SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soft_clf = svm.LinearSVC(C=10**1)\n",
    "soft_clf.fit(train_LSI, train_target_group)\n",
    "soft_svm_predicted = soft_clf.predict(test_LSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft_SVM-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "test_set = data_fun('test')\n",
    "test_target_group = [ int(x / 4) for x in test_set.target]\n",
    "y_score_test_soft_svm = soft_clf.decision_function(test_LSI)\n",
    "\n",
    "#print(test_target_group[0:10])\n",
    "#print(y_score_test.shape)\n",
    "#print(y_score_test[0:10])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_target_group, y_score_test_soft_svm)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC_SVM_soft Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft_SVM Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test_target_group, soft_svm_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft_clf-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "soft_clf_accuracy = accuracy_score(test_target_group, soft_svm_predicted)\n",
    "print (soft_clf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "soft_clf_precision_score = precision_score(test_target_group, soft_svm_predicted)\n",
    "print (soft_clf_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "soft_clf_recall_score = recall_score(test_target_group, soft_svm_predicted)\n",
    "print (soft_clf_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian-NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_LSI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-83e6320de25d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnb_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnb_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_LSI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnb_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_LSI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnb_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_LSI' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(train_LSI, train_target_group)\n",
    "nb_predicted = nb_clf.predict(test_LSI)\n",
    "print (nb_predicted.shape)\n",
    "print (nb_predicted[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian-NB-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "test_set = data_fun('test')\n",
    "test_target_group = [ int(x / 4) for x in test_set.target]\n",
    "y_score_test_nb = nb_clf.predict_proba(test_LSI)[:,1]\n",
    "\n",
    "#print(y_score_test_nb.shape)\n",
    "#print(y_score_test_nb[0:10])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_target_group, y_score_test_nb)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC_NB Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian-NB-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test_target_group, nb_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian-NB-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nb_accuracy = accuracy_score(test_target_group, nb_predicted)\n",
    "print (nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "nb_precision_score = precision_score(test_target_group, nb_predicted)\n",
    "print (nb_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "nb_recall_score = recall_score(test_target_group, nb_predicted)\n",
    "print (nb_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian-NB-Recall and Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "y_score_test_nb = nb_clf.predict_proba(test_LSI)[:,1]\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "precision, recall, _ = precision_recall_curve(test_target_group,y_score_test_nb)\n",
    "average_precision = average_precision_score(test_target_group, y_score_test_nb)\n",
    "#print (precision[0:10])\n",
    "#print (recall[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli-NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3150,)\n",
      "[0 0 0 0 0 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_clf = BernoulliNB()\n",
    "nb_clf.fit(train_LSI, train_target_group)\n",
    "nb_predicted = nb_clf.predict(test_LSI)\n",
    "print (nb_predicted.shape)\n",
    "print (nb_predicted[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli-NB-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "test_set = data_fun('test')\n",
    "test_target_group = [ int(x / 4) for x in test_set.target]\n",
    "y_score_test_nb = nb_clf.predict_proba(test_LSI)[:,1]\n",
    "\n",
    "#print(y_score_test_nb.shape)\n",
    "#print(y_score_test_nb[0:10])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_target_group, y_score_test_nb)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC_NB Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli-NB-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test_target_group, nb_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli-NB-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nb_accuracy = accuracy_score(test_target_group, nb_predicted)\n",
    "print (nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "nb_precision_score = precision_score(test_target_group, nb_predicted)\n",
    "print (nb_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "nb_recall_score = recall_score(test_target_group, nb_predicted)\n",
    "print (nb_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli-NB-Recall and Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "y_score_test_nb = nb_clf.predict_proba(test_LSI)[:,1]\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "precision, recall, _ = precision_recall_curve(test_target_group,y_score_test_nb)\n",
    "average_precision = average_precision_score(test_target_group, y_score_test_nb)\n",
    "#print (precision[0:10])\n",
    "#print (recall[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### LR classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(train_LSI, train_target_group)\n",
    "lr_predicted = logreg.predict(test_LSI)\n",
    "print (lr_predicted.shape)\n",
    "print (lr_predicted[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "test_set = data_fun('test')\n",
    "test_target_group = [ int(x / 4) for x in test_set.target]\n",
    "y_score_test_lr = logreg.decision_function(test_LSI)\n",
    "#y_score_test_lr = logreg.predict_proba(test_LSI)[:,1]\n",
    "\n",
    "#print(y_score_test_lr.shape)\n",
    "#print(y_score_test_lr[0:10])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_target_group, y_score_test_lr)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC_LR Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test_target_group, lr_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "lr_accuracy = accuracy_score(test_target_group, lr_predicted)\n",
    "print (lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "lr_precision_score = precision_score(test_target_group, lr_predicted)\n",
    "print (lr_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "lr_recall_score = recall_score(test_target_group, lr_predicted)\n",
    "print (lr_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR-Recall and Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "y_score_test_lr = logreg.decision_function(test_LSI)\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "precision, recall, _ = precision_recall_curve(test_target_group,y_score_test_lr)\n",
    "average_precision = average_precision_score(test_target_group, y_score_test_lr)\n",
    "#print (precision[0:10])\n",
    "#print (recall[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions to get data or LSI for train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories_i = ['comp.sys.ibm.pc.hardware','comp.sys.mac.hardware','misc.forsale','soc.religion.christian']\n",
    "\n",
    "def data_fun_i(train_or_test):\n",
    "    if(train_or_test == 'train'):\n",
    "        data = fetch_20newsgroups(subset='train', categories=categories_i, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "    if(train_or_test == 'test'):\n",
    "        data = fetch_20newsgroups(subset='test', categories=categories_i, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "    return data\n",
    "\n",
    "def LSI_fun_i(train_or_test):\n",
    "    if(train_or_test == 'train'):\n",
    "        data = fetch_20newsgroups(subset='train', categories=categories_i, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "        TFxIDF_sub = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}',)\n",
    "        TFxIDF_sub_data = TFxIDF_sub.fit_transform(data.data)\n",
    "        Y = TruncatedSVD(n_components=50, algorithm='arpack')\n",
    "        sub_LSI = Y.fit_transform(TFxIDF_sub_data)\n",
    "    if(train_or_test == 'test'):\n",
    "        data = fetch_20newsgroups(subset='test', categories=categories_i, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "        TFxIDF_sub = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}',)\n",
    "        TFxIDF_sub_data = TFxIDF_sub.fit_transform(data.data)\n",
    "        Y = TruncatedSVD(n_components=50, algorithm='arpack')\n",
    "        sub_LSI = Y.fit_transform(TFxIDF_sub_data)\n",
    "    return sub_LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier \n",
    "from sklearn.multiclass import OneVsOneClassifier \n",
    "from sklearn.svm import LinearSVC\n",
    "train_LSI_i = LSI_fun_i('train')\n",
    "train_set_i = data_fun_i('train')\n",
    "test_LSI_i = LSI_fun_i('test')\n",
    "test_set_i = data_fun_i('test')\n",
    "#train_target_group_i = [ int(x / 10) for x in train_set_i.target]\n",
    "#test_target_group_i = [int(x / 10) for x in test_set_i.target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one vs rest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ovr_classifier_i = OneVsRestClassifier (LinearSVC())\n",
    "ovr_classifier_i.fit(train_LSI_i, train_set_i.target)\n",
    "ovr_predict_i = ovr_classifier_i.predict(test_LSI_i)\n",
    "#print (ovr_predict_i[0:4])\n",
    "print (ovr_predict_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVR-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_set_i.target, ovr_predict_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVR-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ovr_accuracy = accuracy_score(test_set_i.target, ovr_predict_i)\n",
    "print (ovr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "ovr_precision_score = precision_score(test_set_i.target, ovr_predict_i,average='weighted')\n",
    "print (ovr_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "ovr_recall_score = recall_score(test_set_i.target, ovr_predict_i,average='weighted')\n",
    "print (ovr_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one vs one classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ovo_classifier_i = OneVsOneClassifier (LinearSVC())\n",
    "ovo_classifier_i.fit(train_LSI_i, train_set_i.target)\n",
    "ovo_predict_i = ovo_classifier_i.predict(test_LSI_i)\n",
    "print (ovo_predict_i.shape)\n",
    "print (ovo_predict_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVO-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_set_i.target, ovo_predict_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVO-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ovo_accuracy = accuracy_score(test_set_i.target, ovo_predict_i)\n",
    "print (ovo_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "ovo_precision_score = precision_score(test_set_i.target, ovo_predict_i,average='weighted')\n",
    "print (ovo_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "ovo_recall_score = recall_score(test_set_i.target, ovo_predict_i,average='weighted')\n",
    "print (ovo_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian NB Multiclass Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1565,)\n",
      "[2 0 3 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classifier_i = GaussianNB()\n",
    "nb_classifier_i.fit(train_LSI_i, train_set_i.target)\n",
    "nb_predict_i = nb_classifier_i.predict(test_LSI_i)\n",
    "print (nb_predict_i.shape)\n",
    "print (nb_predict_i[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian-NB-Multi Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[137, 161,  72,  22],\n",
       "       [109, 127, 105,  44],\n",
       "       [ 79,  45, 204,  62],\n",
       "       [ 97,  18,  56, 227]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_set_i.target, nb_predict_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian-NB-Multi-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.444089456869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nb_accuracy = accuracy_score(test_set_i.target, nb_predict_i)\n",
    "print (nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.449276631965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "nb_precision_score = precision_score(test_set_i.target, nb_predict_i,average='weighted')\n",
    "print (nb_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.444089456869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "nb_recall_score = recall_score(test_set_i.target, nb_predict_i,average='weighted')\n",
    "print (nb_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bernoulli NB Multiclass Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1565,)\n",
      "[2 0 3 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb_classifier_i = BernoulliNB()\n",
    "nb_classifier_i.fit(train_LSI_i, train_set_i.target)\n",
    "nb_predict_i = nb_classifier_i.predict(test_LSI_i)\n",
    "print (nb_predict_i.shape)\n",
    "print (nb_predict_i[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Bernoulli-NB-Multi Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[162, 169,  54,   7],\n",
       "       [189,  89,  80,  27],\n",
       "       [ 57,  23, 296,  14],\n",
       "       [ 10,  27,  48, 313]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_set_i.target, nb_predict_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli-NB-Multi-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.549520766773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nb_accuracy = accuracy_score(test_set_i.target, nb_predict_i)\n",
    "print (nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.542977669991\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "nb_precision_score = precision_score(test_set_i.target, nb_predict_i,average='weighted')\n",
    "print (nb_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.549520766773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "nb_recall_score = recall_score(test_set_i.target, nb_predict_i,average='weighted')\n",
    "print (nb_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB Multiclass Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-e718965d3ad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnb_classifier_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnb_classifier_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_LSI_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnb_predict_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_classifier_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_LSI_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnb_predict_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/qinyiyan/anaconda/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    550\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[1;32m    551\u001b[0m                                        dtype=np.float64)\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_class_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_prior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/qinyiyan/anaconda/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input X must be non-negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_classifier_i = MultinomialNB()\n",
    "nb_classifier_i.fit(train_LSI_i, train_set_i.target)\n",
    "nb_predict_i = nb_classifier_i.predict(test_LSI_i)\n",
    "print (nb_predict_i.shape)\n",
    "print (nb_predict_i[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial-NB-Multi Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[162, 169,  54,   7],\n",
       "       [189,  89,  80,  27],\n",
       "       [ 57,  23, 296,  14],\n",
       "       [ 10,  27,  48, 313]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_set_i.target, nb_predict_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli-NB-Multi-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.549520766773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nb_accuracy = accuracy_score(test_set_i.target, nb_predict_i)\n",
    "print (nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.542977669991\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "nb_precision_score = precision_score(test_set_i.target, nb_predict_i,average='weighted')\n",
    "print (nb_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.549520766773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "nb_recall_score = recall_score(test_set_i.target, nb_predict_i,average='weighted')\n",
    "print (nb_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
