{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group1 is:  3903 , Group2 is:  3979\n"
     ]
    }
   ],
   "source": [
    "# from matplotlib import pyplot\n",
    "import os\n",
    "\n",
    "#define a function to count the document number \n",
    "def Count(dirname):\n",
    "  count=0\n",
    "  for item in os.listdir(dirname):\n",
    "    count+=1\n",
    "  return count\n",
    "\n",
    "counter=[]\n",
    "\n",
    "#plot the histogram for 20 topics\n",
    "for dir in os.listdir('20news-bydate-train'):\n",
    "  dir_name='20news-bydate-train/'+dir\n",
    "  count1=Count(dir_name)\n",
    "  counter.append(count1)\n",
    "\n",
    "i=0;\n",
    "\n",
    "for dir in os.listdir('20news-bydate-test'):\n",
    "  #print counter[i],'\\n'\n",
    "  dir_name='20news-bydate-test/'+dir\n",
    "  count2=Count(dir_name)\n",
    "  counter[i]+=count2\n",
    "  #print counter[i],'\\n'\n",
    "  i+=1\n",
    "  \n",
    "#count the document number for the two groups\n",
    "new_counter=[0,0]\n",
    "for dir in os.listdir('20news-bydate-train'):\n",
    "  if(dir=='comp.graphics' or dir=='comp.os.ms-windows.misc' or dir=='comp.sys.ibm.pc.hardware' or dir=='comp.sys.mac.hardware'):\n",
    "    dir_name='20news-bydate-train/'+dir\n",
    "    count1=Count(dir_name)\n",
    "    new_counter[0]+=count1\n",
    "    #print (new_counter[0],'\\n')\n",
    "  if(dir=='rec.autos' or dir=='rec.motorcycles' or dir=='rec.sport.baseball' or dir=='rec.sport.hockey'):\n",
    "    dir_name='20news-bydate-train/'+dir\n",
    "    count1=Count(dir_name)\n",
    "    new_counter[1]+=count1\n",
    "    #print (new_counter[1],'\\n')\n",
    "    \n",
    "for dir in os.listdir('20news-bydate-test'):\n",
    "  if(dir=='comp.graphics' or dir=='comp.os.ms-windows.misc' or dir=='comp.sys.ibm.pc.hardware' or dir=='comp.sys.mac.hardware'):\n",
    "    dir_name='20news-bydate-test/'+dir\n",
    "    count2=Count(dir_name)\n",
    "    new_counter[0]+=count2\n",
    "    #print (new_counter[0],'\\n')\n",
    "  if(dir=='rec.autos' or dir=='rec.motorcycles' or dir=='rec.sport.baseball' or dir=='rec.sport.hockey'):\n",
    "    dir_name='20news-bydate-test/'+dir\n",
    "    count2=Count(dir_name)\n",
    "    new_counter[1]+=count2\n",
    "    #print (new_counter[1],'\\n')\n",
    "\n",
    "print ('Group1 is: ',new_counter[0],', Group2 is: ',new_counter[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ziyin\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "n = 20\n",
    "values = (counter[0],counter[1],counter[2],counter[3],counter[4],counter[5],counter[6],counter[7],counter[8],counter[9],counter[10],counter[11],counter[12],counter[13],counter[14],counter[15],counter[16],counter[17],counter[18],counter[19])\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n)\n",
    "bar_width = 0.35\n",
    "opacity = 1.0\n",
    "bars = plt.bar(index, values, bar_width,alpha = opacity, color = 'b')\n",
    "plt.xlabel('Topics')\n",
    "plt.xlabel('Documents')\n",
    "plt.title('Number of documents per topic')\n",
    "plt.xticks(index + bar_width, ('1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20'))\n",
    "plt.ylim(0,1000)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 72399)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "#nltk.download()\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def tokenizer_fun(text):\n",
    "    new_text = re.sub(r'[^A-Za-z]', \" \", text)\n",
    "    tokens =[word for sent in nltk.sent_tokenize(new_text) for word in nltk.word_tokenize(sent)]\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]{2,}', token):\n",
    "            new_tokens.append(token)     \n",
    "    stem = [stemmer.stem(t) for t in new_tokens]\n",
    "    return stem\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "all_data = fetch_20newsgroups(subset='all', shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TFxIDF = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}',)\n",
    "TFxIDF_data = TFxIDF.fit_transform(all_data.data)\n",
    "count = TFxIDF_data.shape\n",
    "\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['card', 'drive', 'ani', 'scsi', 'work', 'mb', 'control', 'problem', 'use', 'disk'])\n",
      "dict_keys(['drive', 'appl', 'mac', 'ani', 'like', 'work', 'know', 'monitor', 'problem', 'use'])\n",
      "dict_keys(['includ', 'drive', 'sell', 'pleas', 'new', 'ship', 'sale', 'price', 'offer', 'use'])\n",
      "dict_keys(['god', 'peopl', 'believ', 'think', 'jesus', 'christian', 'church', 'sin', 'say', 'know'])\n"
     ]
    }
   ],
   "source": [
    "list=['comp.sys.ibm.pc.hardware','comp.sys.mac.hardware','misc.forsale','soc.religion.christian']\n",
    "\n",
    "for category in list:\n",
    "    categories = [category]\n",
    "    sub_data = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "    TFxIDF_sub = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, max_features=10, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}')\n",
    "    sub_count = TFxIDF_sub.fit_transform(sub_data.data)\n",
    "    #print (sub_count)\n",
    "    print (TFxIDF_sub.vocabulary_.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Problem(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "X = TruncatedSVD(n_components=50)\n",
    "LSI = X.fit_transform(TFxIDF_data)\n",
    "#print (LSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Problem(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to get data or LSI for train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4154, 50)\n",
      "(2765, 50)\n"
     ]
    }
   ],
   "source": [
    "categories = ['comp.graphics','comp.os.ms-windows.misc','comp.sys.ibm.pc.hardware','comp.sys.ibm.pc.hardware','rec.autos','rec.motorcycles','rec.sport.baseball','rec.sport.hockey']\n",
    "\n",
    "def data_fun(train_or_test):\n",
    "    if(train_or_test == 'train'):\n",
    "        data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "    if(train_or_test == 'test'):\n",
    "        data = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "    return data  \n",
    "\n",
    "def LSI_fun(train_or_test):\n",
    "    if(train_or_test == 'train'):\n",
    "        data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "        TFxIDF_sub = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}',)\n",
    "        TFxIDF_sub_data = TFxIDF_sub.fit_transform(data.data)\n",
    "        Y = TruncatedSVD(n_components=50)\n",
    "        sub_LSI = Y.fit_transform(TFxIDF_sub_data)\n",
    "    if(train_or_test == 'test'):\n",
    "        data = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "        TFxIDF_sub = TfidfVectorizer(analyzer='word',tokenizer=tokenizer_fun, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}',)\n",
    "        TFxIDF_sub_data = TFxIDF_sub.fit_transform(data.data)\n",
    "        Y = TruncatedSVD(n_components=50)\n",
    "        sub_LSI = Y.fit_transform(TFxIDF_sub_data)\n",
    "    return sub_LSI \n",
    "\n",
    "new_LSI = LSI_fun('train')\n",
    "print (new_LSI.shape)\n",
    "\n",
    "new_LSI = LSI_fun('test')\n",
    "print (new_LSI.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 7 4 6 1 2 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "lin_clf = svm.LinearSVC()\n",
    "# print(all_data.target)\n",
    "train_LSI = LSI_fun('train')\n",
    "train_set = data_fun('train')\n",
    "\n",
    "train_target_group = [ int(x / 10) for x in train_set.target]\n",
    "# print(train_target_group)\n",
    "print(train_set.target[0:20])\n",
    "# lin_clf.fit(train_LSI, train_set.target)\n",
    "lin_clf.fit(train_LSI, train_target_group)\n",
    "#lin_clf.fit(train_LSI, train_set.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2765, 50)\n",
      "[0 1 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "test_LSI = LSI_fun('test')\n",
    "print(test_LSI.shape)\n",
    "svm_predicted = lin_clf.predict(test_LSI)\n",
    "print (svm_predicted[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0]\n",
      "(2765,)\n",
      "[-0.8258543   1.07265862 -0.22201801  1.10889407]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "test_set = data_fun('test')\n",
    "test_target_group = [ int(x / 10) for x in test_set.target]\n",
    "y_score_test = lin_clf.decision_function(test_LSI)\n",
    "\n",
    "\n",
    "print(test_target_group[0:10])\n",
    "print(y_score_test.shape)\n",
    "print(y_score_test[0:10])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_target_group, y_score_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 342,  833],\n",
       "       [1394,  196]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_target_group, svm_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.194575045208\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "svm_accuracy = accuracy_score(test_target_group, svm_predicted)\n",
    "print (svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.650690283928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "svm_precision_score = precision_score(test_target_group, svm_predicted)\n",
    "print (svm_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.679358172423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "svm_recall_score = recall_score(test_target_group, svm_predicted)\n",
    "print (svm_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM-Recall and Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48837827  0.48831031  0.48837518  0.48844007  0.48850498  0.48856991\n",
      "  0.48863485  0.48869981  0.48876479  0.48882979]\n",
      "[ 1.          0.99972804  0.99972804  0.99972804  0.99972804  0.99972804\n",
      "  0.99972804  0.99972804  0.99972804  0.99972804]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "precision, recall, _ = precision_recall_curve(test_target_group,y_score_test)\n",
    "average_precision = average_precision_score(test_target_group, y_score_test)\n",
    "print (precision[0:10])\n",
    "print (recall[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7532,)\n",
      "[1 0 1 1 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(train_LSI, train_target_group)\n",
    "nb_predicted = naive_clf.predict(test_LSI)\n",
    "print (nb_predicted.shape)\n",
    "print (nb_predicted[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7532,)\n",
      "[  9.98215497e-01   3.75858161e-04   9.99999024e-01   9.62466911e-01\n",
      "   1.00000000e+00   1.32571625e-02   2.31623718e-04   7.25040868e-04\n",
      "   8.01744106e-04   2.58492837e-02]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "test_set = data_fun('test')\n",
    "test_target_group = [ int(x / 10) for x in test_set.target]\n",
    "y_score_test_nb = nb_clf.predict_proba(test_LSI)[:,1]\n",
    "\n",
    "\n",
    "print(y_score_test_nb.shape)\n",
    "print(y_score_test_nb[0:10])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_target_group, y_score_test_nb)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2629, 1226],\n",
       "       [1965, 1712]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test_target_group, nb_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5763409453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nb_accuracy = accuracy_score(test_target_group, nb_predicted)\n",
    "print (nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582709326072\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "nb_precision_score = precision_score(test_target_group, nb_predicted)\n",
    "print (nb_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.465596954039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "nb_recall_score = recall_score(test_target_group, nb_predicted)\n",
    "print (nb_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB-Recall and Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48818375  0.48811579  0.48804781  0.48811263  0.48817747  0.48824233\n",
      "  0.48817433  0.4882392   0.48830409  0.488369  ]\n",
      "[ 1.          0.99972804  0.99945608  0.99945608  0.99945608  0.99945608\n",
      "  0.99918412  0.99918412  0.99918412  0.99918412]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "y_score_test_nb = nb_clf.predict_proba(test_LSI)[:,1]\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "precision, recall, _ = precision_recall_curve(test_target_group,y_score_test_nb)\n",
    "average_precision = average_precision_score(test_target_group, y_score_test_nb)\n",
    "print (precision[0:10])\n",
    "print (recall[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LR classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7532,)\n",
      "[0 1 0 1 0 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(train_LSI, train_target_group)\n",
    "lr_predicted = logreg.predict(test_LSI)\n",
    "print (lr_predicted.shape)\n",
    "print (lr_predicted[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7532,)\n",
      "[-3.26845382  0.16877386 -4.95827412  3.6898236  -6.72444147  0.28711841\n",
      "  2.15477778 -6.0935701  -2.88783226 -2.91196545]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "test_set = data_fun('test')\n",
    "test_target_group = [ int(x / 10) for x in test_set.target]\n",
    "y_score_test_lr = logreg.decision_function(test_LSI)\n",
    "#y_score_test_lr = logreg.predict_proba(test_LSI)[:,1]\n",
    "\n",
    "print(y_score_test_lr.shape)\n",
    "print(y_score_test_lr[0:10])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_target_group, y_score_test_lr)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR-Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2535, 1320],\n",
       "       [1356, 2321]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test_target_group, lr_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR-Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.644715878917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "lr_accuracy = accuracy_score(test_target_group, lr_predicted)\n",
    "print (lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63746223565\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "lr_precision_score = precision_score(test_target_group, lr_predicted)\n",
    "print (lr_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.631221104161\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "lr_recall_score = recall_score(test_target_group, lr_predicted)\n",
    "print (lr_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR-Recall and Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49000533  0.48993736  0.49000267  0.49006799  0.49013333  0.49019869\n",
      "  0.49026407  0.49019608  0.49026147  0.49032688]\n",
      "[ 1.          0.99972804  0.99972804  0.99972804  0.99972804  0.99972804\n",
      "  0.99972804  0.99945608  0.99945608  0.99945608]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "y_score_test_lr = logreg.decision_function(test_LSI)\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "precision, recall, _ = precision_recall_curve(test_target_group,y_score_test_lr)\n",
    "average_precision = average_precision_score(test_target_group, y_score_test_lr)\n",
    "print (precision[0:10])\n",
    "print (recall[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
